**What is algorithmic complexity? Time complexity (O(n), O(log n), O(n^2)) and space complexity.**

## **What is it**

**Algorithmic complexity** refers to how the performance of an algorithm changes with the size of the input. It helps estimate the **efficiency** of an algorithm in terms of:

1. **Time Complexity** – How the _runtime_ increases as the input grows.
2. **Space Complexity** – How the _memory usage_ increases as the input grows.
    

---

## ✅ **Time Complexity**

Time complexity expresses the **number of operations** an algorithm performs as a function of the input size `n`.

### Common Time Complexities (from best to worst):

|Complexity|Description|Example|
|---|---|---|
|**O(1)**|Constant time – independent of input size|Accessing an array element: `arr[5]`|
|**O(log n)**|Logarithmic time|Binary search in a sorted array|
|**O(n)**|Linear time|Looping through an array|
|**O(n log n)**|Linearithmic time|Efficient sorting: Merge sort, Quick sort|
|**O(n²)**|Quadratic time|Nested loops: Bubble sort|
|**O(2ⁿ)**|Exponential time|Recursive Fibonacci (without memoization)|
|**O(n!)**|Factorial time|Solving the Traveling Salesman problem|

---

## ✅ **Space Complexity**

Space complexity measures how much **extra memory** (aside from the input) an algorithm uses.

- **O(1):** Constant space (e.g., a few variables)
- **O(n):** Space grows linearly with input size (e.g., storing an extra array)
- **O(n²):** Used for 2D arrays or nested data structures
    